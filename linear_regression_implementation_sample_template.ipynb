{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b69e8b",
   "metadata": {},
   "source": [
    "# Linear Regression Implementation Assignment [Sample Template]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec0f44",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a665a92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Tuple, Union, Dict, Any, List\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ABC, abstractmethod\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Optional, Tuple, Union, Dict, Any, List\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression as SklearnLinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fbf9e",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ae5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a50aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "\n",
    "# Split the data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8eb14",
   "metadata": {},
   "source": [
    "## Base Linear Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseLinearRegression(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for linear regression implementations.\n",
    "    \n",
    "    This class defines the common interface and shared functionality for\n",
    "    different linear regression algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fit_intercept : bool, default=True\n",
    "        Whether to calculate the intercept for this model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fit_intercept: bool = True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.coef_: Optional[np.ndarray] = None\n",
    "        self.intercept_: Optional[float] = None\n",
    "        self.n_features_in_: Optional[int] = None\n",
    "        \n",
    "    def _validate_input(self, X: np.ndarray, y: Optional[np.ndarray] = None) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Validate and preprocess input data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input features\n",
    "        y : array-like of shape (n_samples,), optional\n",
    "            Target values\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        X_processed : np.ndarray\n",
    "            Processed feature matrix\n",
    "        y_processed : np.ndarray or None\n",
    "            Processed target vector\n",
    "        \"\"\"\n",
    "        # Convert to numpy array\n",
    "        pass\n",
    "    \n",
    "    def _add_intercept(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Add intercept column to feature matrix if fit_intercept is True.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'BaseLinearRegression':\n",
    "        \"\"\"\n",
    "        Fit the linear regression model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : BaseLinearRegression\n",
    "            Returns self for method chaining\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Make predictions using the linear model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Samples to predict\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : np.ndarray of shape (n_samples,)\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "        # Check if model is fitted\n",
    "        \n",
    "        # Make predictions\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Return the coefficient of determination R^2 of the prediction.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Test samples\n",
    "        y : array-like of shape (n_samples,)\n",
    "            True values for X\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            R score\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af676f91",
   "metadata": {},
   "source": [
    "## Gradient Descent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513eaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD(BaseLinearRegression):\n",
    "    \"\"\"\n",
    "    Linear Regression using Gradient Descent with SSE cost function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : float, default=0.01\n",
    "        The step size for gradient descent updates\n",
    "    max_iter : int, default=1000\n",
    "        Maximum number of iterations for gradient descent\n",
    "    tol : float, default=1e-6\n",
    "        Tolerance for convergence criterion\n",
    "    batch_size : int, default=32\n",
    "        Size of mini-batches for gradient descent\n",
    "    random_state : int, optional\n",
    "        Random seed for reproducibility\n",
    "    fit_intercept : bool, default=True\n",
    "        Whether to fit an intercept term\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learning_rate: float = 0.01,\n",
    "                 max_iter: int = 1000,\n",
    "                 tol: float = 1e-6,\n",
    "                 batch_size: int = 32,\n",
    "                 random_state: Optional[int] = None,\n",
    "                 fit_intercept: bool = True):\n",
    "        super().__init__(fit_intercept=fit_intercept)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.batch_size = batch_size\n",
    "        self.random_state = random_state\n",
    "        self.cost_history_: List[float] = []\n",
    "        self.n_iter_: Optional[int] = None\n",
    "\n",
    "    def _compute_cost(self, X: np.ndarray, y: np.ndarray, theta: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compute the SSE cost function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix with intercept column if fit_intercept=True\n",
    "        y : np.ndarray\n",
    "            Target values\n",
    "        theta : np.ndarray\n",
    "            Parameter vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cost : float\n",
    "            SSE cost value\n",
    "        \"\"\"\n",
    "        # TODO: Implement SSE cost function\n",
    "        # J(theta) = (1/2m) * sum((X @ theta - y)^2)\n",
    "        pass\n",
    "\n",
    "    def _compute_gradients(self, X: np.ndarray, y: np.ndarray, theta: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute gradients of the cost function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix with intercept column if fit_intercept=True\n",
    "        y : np.ndarray\n",
    "            Target values\n",
    "        theta : np.ndarray\n",
    "            Parameter vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gradients : np.ndarray\n",
    "            Gradient vector\n",
    "        \"\"\"\n",
    "        # TODO: Implement gradient computation\n",
    "        pass\n",
    "\n",
    "    def _get_mini_batches(self, X: np.ndarray, y: np.ndarray) -> list:\n",
    "        \"\"\"Generate mini-batches for stochastic gradient descent.\"\"\"\n",
    "        \n",
    "        # Create mini-batches\n",
    "        pass\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'LinearRegressionGD':\n",
    "        \"\"\"\n",
    "        Fit the model using gradient descent.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : LinearRegressionGD\n",
    "            Returns self for method chaining\n",
    "        \"\"\"\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6a87e",
   "metadata": {},
   "source": [
    "## Normal Equation Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82aea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionNE(BaseLinearRegression):\n",
    "    \"\"\"\n",
    "    Linear Regression using Normal Equation (closed-form solution).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fit_intercept : bool, default=True\n",
    "        Whether to fit an intercept term\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fit_intercept: bool = True):\n",
    "        super().__init__(fit_intercept=fit_intercept)\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'LinearRegressionNE':\n",
    "        \"\"\"\n",
    "        Fit the model using the normal equation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : LinearRegressionNE\n",
    "            Returns self for method chaining\n",
    "        \"\"\" \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4834aa4",
   "metadata": {},
   "source": [
    "## Unit Tests [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb34840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_linear_regression_implementations():\n",
    "    \"\"\"\n",
    "    Unit tests for linear regression implementations.\n",
    "    \"\"\"\n",
    "    print(\"Running unit tests...\")\n",
    "    \n",
    "    # Test data: simple 2D problem\n",
    "    np.random.seed(42)\n",
    "    X_test = np.random.randn(100, 2)\n",
    "    true_coef = np.array([3.0, -2.0])\n",
    "    true_intercept = 1.5\n",
    "    y_test = X_test @ true_coef + true_intercept + 0.1 * np.random.randn(100)\n",
    "    \n",
    "    # Test 1: Basic functionality\n",
    "    print(\"\\nTest 1: Basic functionality\")\n",
    "    try:\n",
    "        # Test GD implementation\n",
    "        gd_model = LinearRegressionGD(learning_rate=0.01, max_iter=1000, random_state=42)\n",
    "        gd_model.fit(X_test, y_test)\n",
    "        gd_pred = gd_model.predict(X_test)\n",
    "        gd_score = gd_model.score(X_test, y_test)\n",
    "        \n",
    "        # Test NE implementation\n",
    "        ne_model = LinearRegressionNE()\n",
    "        ne_model.fit(X_test, y_test)\n",
    "        ne_pred = ne_model.predict(X_test)\n",
    "        ne_score = ne_model.score(X_test, y_test)\n",
    "        \n",
    "        print(\"+ Both models fit and predict successfully\")\n",
    "        print(f\"+ GD R^2 score: {gd_score:.4f}\")\n",
    "        print(f\"+ NE R^2 score: {ne_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"- Test 1 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 2: Shape validation\n",
    "    print(\"\\nTest 2: Input validation\")\n",
    "    try:\n",
    "        model = LinearRegressionGD()\n",
    "        \n",
    "        # Test wrong X dimensions\n",
    "        try:\n",
    "            model.fit(np.array([1, 2, 3]), y_test)\n",
    "            print(\"- Should have raised error for 1D X\")\n",
    "            return False\n",
    "        except ValueError:\n",
    "            print(\"+ Correctly rejected 1D X input\")\n",
    "        \n",
    "        # Test mismatched X and y shapes\n",
    "        try:\n",
    "            model.fit(X_test, y_test[:-10])\n",
    "            print(\"- Should have raised error for mismatched shapes\")\n",
    "            return False\n",
    "        except ValueError:\n",
    "            print(\"+ Correctly rejected mismatched X and y shapes\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"- Test 2 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 3: fit_intercept parameter\n",
    "    print(\"\\nTest 3: fit_intercept parameter\")\n",
    "    try:\n",
    "        # With intercept\n",
    "        model_with_intercept = LinearRegressionNE(fit_intercept=True)\n",
    "        model_with_intercept.fit(X_test, y_test)\n",
    "        \n",
    "        # Without intercept\n",
    "        model_without_intercept = LinearRegressionNE(fit_intercept=False)\n",
    "        model_without_intercept.fit(X_test, y_test)\n",
    "        \n",
    "        print(\"+ fit_intercept parameter works for both True and False\")\n",
    "        print(f\"+ With intercept: coef shape {model_with_intercept.coef_.shape}, intercept: {model_with_intercept.intercept_:.4f}\")\n",
    "        print(f\"+ Without intercept: coef shape {model_without_intercept.coef_.shape}, intercept: {model_without_intercept.intercept_:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"- Test 3 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 4: Prediction before fitting\n",
    "    print(\"\\nTest 4: Prediction before fitting\")\n",
    "    try:\n",
    "        unfitted_model = LinearRegressionGD()\n",
    "        try:\n",
    "            unfitted_model.predict(X_test)\n",
    "            print(\"- Should have raised error for unfitted model\")\n",
    "            return False\n",
    "        except ValueError:\n",
    "            print(\"+ Correctly rejected prediction on unfitted model\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"- Test 4 failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\n++ All unit tests passed!\")\n",
    "    return True\n",
    "\n",
    "# Run the tests\n",
    "test_linear_regression_implementations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be8583",
   "metadata": {},
   "source": [
    "## Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f61e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "\n",
    "# Train models and collect results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06168bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive comparison table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1a354",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d419f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs predicted plots\n",
    "\n",
    "# Training set plots\n",
    "\n",
    "# Test set plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cost history for gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3d7db",
   "metadata": {},
   "source": [
    "## Analysis and Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8311cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
